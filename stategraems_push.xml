<tool id="stategraems_push" name="Save files in STATegra EMS" version="0.2" workflow_compatible="true">
	<description>Automatically annotate and save your Galaxy history files in STATegra EMS.</description>
	<requirements>
		<requirement type="package">requests</requirement>
	</requirements>

	<command interpreter="python">
		##------------------------------------------------------------------------------------
		## This function calculates the associations between the different jobs based on the
		## datasets used as input or output for the jobs.
		##------------------------------------------------------------------------------------
		#def findJobAssociations_HistoryDataset($dataset, $job_associations)
			#if ($use_deleted or $dataset.deleted == False) and ($use_hidden or $dataset.visible == True)
				#for $assoc in $dataset.creating_job_associations
					#set $job_associations[$assoc.job.id] = $assoc.job
				#end for
			#end if
		#end def

		##------------------------------------------------------------------------------------
		## This function calculates the associations between the different jobs based on the
		## collection of datasets used as input or output for the jobs.
		##------------------------------------------------------------------------------------
		#def findJobAssociations_HistoryDatasetCollection($dataset_coll, $job_associations)
			#if ($use_deleted or $dataset_coll.deleted == False) and ($use_hidden or $dataset_coll.visible == True)
				$findJobAssociations_HistoryDatasetCollection_rec($dataset_coll, $job_associations)
			#end if
		#end def

		##------------------------------------------------------------------------------------
		## This function calculates recursively the associations between the different jobs
		## based on the collection of datasets used as input or output for the jobs.
		##------------------------------------------------------------------------------------
		#def findJobAssociations_HistoryDatasetCollection_rec($dataset_coll, $job_associations)
			#for $dataset in $dataset_coll.collection.elements
				#if $dataset.hda
					$findJobAssociations_HistoryDataset($dataset.hda, $job_associations)
				##elif $dataset.ldda
					##		#TODO
					##		$enum_LibraryDatasetAssociation($dataset.ldda, $job_associations)
				###elif $dataset.child_collection
				##	$findJobAssociations_HistoryDatasetCollection_rec($dataset.child_collection, $job_associations)
				#end if
			#end for
		#end def

		##------------------------------------------------------------------------------------
		## This function creates a new instance of an Input object that will be added to a
		## job instance
		## https://docs.galaxyproject.org/en/master/_modules/galaxy/model.html#DatasetInstance
		##------------------------------------------------------------------------------------
		#def createInputInstance($jda)
			#set $instance = {}
			#if $jda.dataset
				#set $instance["name"] = str($jda.name)
				#set $instance["id"] = str($__app__.security.encode_id($jda.dataset.id))
				#set $instance["file"] = str($jda.dataset.name)
				#set $instance["external_filename"] = str($jda.dataset.dataset.external_filename)
				#set $instance["file_size"] = str($jda.dataset.dataset.file_size)
			#end if
			#return $instance
		#end def

		##------------------------------------------------------------------------------------
		## This function creates a new instance of an Output object that will be added to a
		## job instance
		##------------------------------------------------------------------------------------
		#def createOutputInstance($jda)
			#set $instance = {}
			#if $jda.dataset
				#set $instance["name"] = str($jda.name)
				#set $instance["id"] = str($__app__.security.encode_id($jda.dataset.id))
				#set $instance["file"] = str($jda.dataset.name)
				#set $instance["file_name"] = str($jda.dataset.dataset.get_file_name())
				#set $instance["external_filename"] = str($jda.dataset.dataset.external_filename)
				#set $instance["file_size"] = str($jda.dataset.dataset.file_size)
				#set $instance["extension"] = str($jda.dataset.extension)
			#end if
			#return $instance
		#end def

		##------------------------------------------------------------------------------------
		## This function creates a new instance of a Parameter object that will be added to a
		## job instance
		##------------------------------------------------------------------------------------
		#def createParameterInstance($parameter_name, $parameter_value)
			##Check if is a dict
			#if isinstance($parameter_value, dict):
				#for $parameter_name_aux, $parameter_value_aux in $parameter_value.items()
					#set $parameterInstance = $createParameterInstance($parameter_name_aux, $parameter_value_aux)
					#if $parameterInstance != ""
						#set $parameter_value[$parameter_name_aux] = $parameterInstance
					#else
						#del $parameter_value[$parameter_name_aux]
					#end if
				#end for
			##Check if is a list
			#else if isinstance($parameter_value, list):
				#set $i = 1
				#set $aux = {}
				#for $parameter_value_aux in $parameter_value
					#set $parameterInstance = $createParameterInstance(str($i), $parameter_value_aux)
					#if $parameterInstance != ""
						#set $aux[$i] = $parameterInstance
						#set $i=$i+1
					#end if
				#end for
				#set $parameter_value = $aux.values()
			##Check if is an object
			#else
				#try
					##Ignore HistoryDatasetAssociation objects and parameters not interesting
					#if ("HistoryDatasetAssociation" in $parameter_value.__class__.__name__) or ($parameter_name.startswith("__")):
						#return ""
					#end if
				#except
					#pass
				#end try

				#set $parameter_value = str($parameter_value)
			#end if

			#set $instance = {"name" : $parameter_name, "value" : $parameter_value}
			#return $instance
		#end def

		##------------------------------------------------------------------------------------
		## This function creates a new instance of Job.
		## https://docs.galaxyproject.org/en/master/_modules/galaxy/model.html#Job
		##------------------------------------------------------------------------------------
		#def createJobInstance($job)
			#set $instance = {}
			#set $instance["id"] = str($job.id)
			#set $instance["tool_id"] = str($job.tool_id)
			#set $instance["tool_version"] = str($job.tool_version)
			#set $instance["state"] = str($job.state)
			#set $instance["exit_code"] = str($job.exit_code)
			#set $instance["inputs"] = []
			#set $instance["outputs"] = []
			#set $instance["parameters"] = []

			#for $input_dataset in $job.input_datasets
				$instance["inputs"].append($createInputInstance($input_dataset))
			#end for

			#for $output_dataset in $job.output_datasets
				$instance["outputs"].append($createOutputInstance($output_dataset))
			#end for

			#if $job.tool_id != "upload1"
				#set $parameters = $job.get_param_values($__app__)
				#for $parameter_name, $parameter_value in $parameters.items()
					#set $parameter = $createParameterInstance($parameter_name, $parameter_value)
					#if $parameter != ""
						$instance["parameters"].append($parameter)
					#end if
				#end for
			#end if

			#return $instance
		#end def

		#def getSelectedDatasets($selectedFiles)
			#set $result = []
			## If input is a data collection
			#if isinstance($selectedFiles, list):
				## For each dataset
				#for $dataset in $selectedFiles:
					$result.append($__app__.security.encode_id('%s' % $dataset.id))
				#end for
			#else:
				$result.append($__app__.security.encode_id('%s' % $dataset.dataset.id))
			#end if
			#return $result
		#end def
		##------------------------------------------------------------------------------------
		## Main body of the tool
		##------------------------------------------------------------------------------------
		## First we process the current history and get a table with the metadata for each job
		#set global $history = $out_file1.creating_job.history
		#set global $use_deleted = True
		#set global $use_hidden = True

		#set $job_associations = {}
		#for $dataset in $history.datasets
			$findJobAssociations_HistoryDataset($dataset, $job_associations)
		#end for
		#for $dataset_coll in $history.dataset_collections
			$findJobAssociations_HistoryDatasetCollection($dataset_coll, $job_associations)
		#end for

		## Now we export the table to a string
		#set $job_table={}
		#for $job_id, $job in $job_associations.iteritems()
			#if $job_id != $out_file1.creating_job.id
				#set $job_table[str($job_id)] = $createJobInstance($job)
			#end if
		#end for

		## Set the params for the next Python script
		#set params={}
		##1. STATegra EMS host
		#set params["ems_host"] = str($emshost)
		##2. STATegra EMS user
		#set params["ems_api_code"] = str($emsapicode)
		##3. New analysis name
		#set params["ems_analysis_name"] = str($emsanalysisname)
		##4. New experiment id
		#set params["ems_experiment_id"] = str($emsexperimentid)
		##5. The selected dataset ids
		#set params["selected_dataset_id"] = $getSelectedDatasets($selectedFiles)
		##6. Upload or not the files
		#if $upload_option.uploadFiles == "upload"
			#set params["upload_option"] = str($upload_option.whichFiles)
		#else
			#set params["upload_option"] = "none"
		#end if
		##7. Current Galaxy user
		#set params["user_name"] = str($__user_name__)
		##8. The history ID
		#set params["history_id"] = $__app__.security.encode_id($out_file1.history.id)
		##9. The working dir for the job
		#set params["job_working_dir"] = str($out_file1.files_path)
		##10. The output file for the job
		#set params["output_file"] = str($out_file1)
		##10. REMOVE ME
		###set params["job_table"] = json.dumps($job_table)


		#import json
		#set $file=open($params["job_working_dir"] + '.tmp', 'w+')
		$file.write(json.dumps($job_table))
		#set $params=json.dumps($params)

		##Execute the main tool script
		stategraems_push.py '$params'
	</command>

	<inputs>
		<param name="emshost" type="text" value="" label="STATegra EMS Host" help="A valid URL to your STATegra EMS host (e.g. http://bioinfo.cipf.es/stategraems)"/>
		<param name="emsapicode" type="text" value="" label="API code:" help="Your API code for STATegraEMS (more info http://stategraems.readthedocs.io/en/latest/tutorials/api/)"/>
		<param name="emsexperimentid" type="text" value="EXP00001" label="Study identifier:" help="A valid identifier for a study in the STATegra EMS (e.g. EXP00001)" />
		<param name="emsanalysisname" type="text" value="My analysis" label="New analysis name:"  help="The name for the new analysis in the STATegra EMS (e.g. My awesome RNA-seq analysis)"/>
		<param format="data" name="selectedFiles" type="data" multiple="true" label="Dataset(s) to annotate:" help="Choose the datasets from the history that will be annotated as part as the new analysis (use control key for multiple selection). Note that all parent steps in the history will be selected automatically."/>
		<conditional name="upload_option">
			<param type="select" display="radio" name="uploadFiles" label="Upload the files? [see help for more information]: ">
				<option value="not_upload">Just send the files description. Do NOT upload the files.</option>
				<option value="upload">Send the description AND the files to STATegra EMS.</option>
			</param>
			<when value="upload">
				<param type="select" display="radio" name="whichFiles" label="Which files do you want to upload? [see help for more information]: ">
					<option value="selected">Upload only the selected files.</option>
					<option value="all">Upload all files, including selected and intermediate files.</option>
				</param>
			</when>
		</conditional>
	</inputs>
	<outputs>
		<data name="out_file1" format="html" file="output.html" />
	</outputs>

	<help>
=======================
Send to STATegra EMS
=======================

**What it does**

Use this tool to automatically annotate your current history in your STATegra EMS instance.
The tool obtains the *file provenance* for each selected file based on the current history and sends it to the STATegra EMS, where a new Analysis instance is created associated to the selected Study.
This Analysis instance will describe the complete process followed to generate the selected files.
Additionally, the resulting files can be stored in the data directory for the selected study.

----

**How to use**

1. Write a valid *URL* to your STATegra EMS host (e.g. http://bioinfo.cipf.es/stategraems)
2. Sign in your STATegra EMS and copy your *API code* (more info http://stategraems.readthedocs.io/en/latest/tutorials/api/)
3. Enter your API code in the form.
4. Type the a valid identifier for a *study* in the STATegra EMS (you must be a valid member of the study, e.g. "EXP00001").
5. Enter a name for the new analysis that will be created in the STATegra EMS (e.g. "My awesome RNA-seq analysis").
6. Choose all the datasets in the history that will be annotated as part as the new analysis.
7. Choose whether you want to send just the description of the datasets generation, or upload the metadata and the generated datasets.

.. class:: infomark

'''TIP''' *Note* that this tool will automatically select all the datasets that are involved in the generation of the selected datasets.

.. class:: infomark

'''TIP''' *Note* that file uploading can fail due to restrictions in file sizes in the STATegra EMS instance.

-----

**Author**: Rafael Hernández de Diego [SLU Global Bioinformatics Centre]

Sources are available at https://github.com/fikipollo/stategraems-galaxy

	</help>
	<citations>
   <citation type="bibtex">@ARTICLE{Hernandez2014,
   author = {Hernandez-de-Diego, R.  and Boix-Chova, N.  and Gomez-Cabrero, D.  and Tegner, J.  and Abugessaisa, I.  and Conesa, A.},
   title = {{S}{T}{A}{T}egra {E}{M}{S}: an {E}xperiment {M}anagement {S}ystem for complex next-generation omics experiments},
   journal = {BMC Syst Biol},
   year = {2014},
   volume = {8 Suppl 2},
   pages = {S9}
   }</citation>
 </citations>
</tool>
